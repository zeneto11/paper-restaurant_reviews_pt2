{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\José\n",
      "[nltk_data]     Neto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset antes da limpeza:\n",
      "(5933, 9)\n",
      "Index(['restaurante_name', 'user_name', 'review_date', 'stars', 'comment_text',\n",
      "       'year', 'platform', 'language', 'comment_text_translated'],\n",
      "      dtype='object')\n",
      "\n",
      "Distribuição por plataforma: platform\n",
      "Google             3917\n",
      "Facebook            847\n",
      "Foursquare          834\n",
      "Yelp                310\n",
      "Zomato               24\n",
      "Restaurant Guru       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Carregar dataset\n",
    "df = pd.read_csv('../datasets/dataset-case_study.csv')\n",
    "\n",
    "# Informações sobre o conjunto de dados\n",
    "print('Dataset antes da limpeza:')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "# Contar quantas linhas tem para cada plataforma\n",
    "platform_counts = df['platform'].value_counts()\n",
    "print(\"\\nDistribuição por plataforma:\", platform_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_text_rows(df):\n",
    "    empty_sentenca_rows = df['comment_text_translated'].isnull() | (df['comment_text_translated'] == '')\n",
    "    # Imprimir o número de sentenças vazias\n",
    "    num_empty_sentences = empty_sentenca_rows.sum()\n",
    "    print(f\"Total de comentários vazios: {num_empty_sentences}\")\n",
    "    print('Removendo comentários vazios...\\n')\n",
    "    # Remover sentenças vazias\n",
    "    df = df[~empty_sentenca_rows]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(df):\n",
    "    rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        sentences = row['comment_text_translated'].split('.')\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if sentence:  # apenas sentenças não vazias\n",
    "                new_row = row.copy()\n",
    "                new_row['comment_text_translated'] = sentence\n",
    "                rows.append(new_row)\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de comentários vazios: 3\n",
      "Removendo comentários vazios...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remover sentenças nulas\n",
    "df = remove_empty_text_rows(df)\n",
    "\n",
    "# Separar os comentários em sentenças\n",
    "df = split_sentences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de comentários vazios: 531\n",
      "Removendo comentários vazios...\n",
      "\n",
      "Total de comentários duplicados: 2101\n",
      "Removendo comentários duplicados...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Substituir espaços múltiplos por um único espaço e realizar strip\n",
    "df['comment_text_translated'] = df['comment_text_translated'].astype(str).apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "# Remover ocorrências de erros\n",
    "replacements = {\n",
    "    'Comida': 'comida',\n",
    "    'Serviço': 'serviço',\n",
    "    'Atmosfera': 'atmosfera',\n",
    "    'Food': 'food',\n",
    "    'Service': 'service',\n",
    "    'Atmosphere': 'atmosphere'\n",
    "}\n",
    "\n",
    "for uppercase, lowercase in replacements.items():\n",
    "    df['comment_text_translated'] = df['comment_text_translated'].str.replace(uppercase, lowercase, regex=False)\n",
    "\n",
    "replacements = [\n",
    "    'comida: 5', 'food: 5', 'comida: 4', 'food: 4', 'comida: 3', 'food: 3', 'comida: 2', 'food: 2', 'comida: 1', 'food: 1',\n",
    "    'serviço: 5', 'service: 5', 'serviço: 4', 'service: 4', 'serviço: 3', 'service: 3', 'serviço: 2', 'service: 2', 'serviço: 1', 'service: 1',\n",
    "    'atmosfera: 5', 'atmosphere: 5', 'atmosfera: 4', 'atmosphere: 4', 'atmosfera: 3', 'atmosphere: 3', 'atmosfera: 2', 'atmosphere: 2', 'atmosfera: 1', 'atmosphere: 1',\n",
    "    ': 5', ': 4', ': 3', ': 2', ': 1'\n",
    "]\n",
    "\n",
    "for r in replacements:\n",
    "    df['comment_text_translated'] = df['comment_text_translated'].str.replace(r, '')\n",
    "\n",
    "# Substituir espaços múltiplos por um único espaço e realizar strip\n",
    "df['comment_text_translated'] = df['comment_text_translated'].astype(str).apply(lambda x: ' '.join(x.split()))\n",
    "\n",
    "# Remover sentenças nulas\n",
    "df = remove_empty_text_rows(df)\n",
    "\n",
    "# Remover sentenças duplicadas\n",
    "comentarios_duplicados = df.duplicated(subset=\"comment_text_translated\").sum()\n",
    "print(\"Total de comentários duplicados:\", comentarios_duplicados)\n",
    "print('Removendo comentários duplicados...\\n')\n",
    "df = df.drop_duplicates(subset=\"comment_text_translated\", keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar Stemming\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "df['comment_text_translated'] = df['comment_text_translated'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset após limpeza:\n",
      "(13733, 9)\n",
      "\n",
      "Distribuição por plataforma: platform\n",
      "Google             8322\n",
      "Yelp               2345\n",
      "Facebook           1559\n",
      "Foursquare         1368\n",
      "Zomato              124\n",
      "Restaurant Guru      15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Informações sobre o conjunto de dados\n",
    "print('Dataset após limpeza:')\n",
    "print(df.shape)\n",
    "\n",
    "# Contar quantas linhas tem para cada plataforma\n",
    "platform_counts = df['platform'].value_counts()\n",
    "print(\"\\nDistribuição por plataforma:\", platform_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'teste2'\n",
    "df.to_csv(f'../datasets/dataset-case_study-{name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
